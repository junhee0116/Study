{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9f6dea",
   "metadata": {},
   "source": [
    "# 머신러닝을 위한 파이썬 라이브러리, scikit-learn\n",
    "\n",
    "![scikit-learn logo.png](https://drive.google.com/uc?id=1Aeb0mBJzYgz7UGmHAdGsQJF44EM9mNTD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5a2da",
   "metadata": {},
   "source": [
    "## scikit-learn 특징\n",
    "\n",
    "* 다양한 머신러닝 알고리즘을 구현한 파이썬 라이브러리\n",
    "* 심플하고 일관성 있는 API, 유용한 온라인 문서, 풍부한 예제\n",
    "* 머신러닝을 위한 쉽고 효율적인 개발 라이브러리 제공\n",
    "* 다양한 머신러닝 관련 알고리즘과 개발을 위한 프레임워크와 API 제공\n",
    "* 많은 사람들이 사용하며 다양한 환경에서 검증된 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f40cf9",
   "metadata": {},
   "source": [
    "## scikit-learn 주요 모듈\n",
    "\n",
    "| 모듈 | 설명 |\n",
    "|------|------|\n",
    "| `sklearn.datasets` | 내장된 예제 데이터 세트 |\n",
    "| `sklearn.preprocessing` | 다양한 데이터 전처리 기능 제공 (변환, 정규화, 스케일링 등) |\n",
    "| `sklearn.feature_selection` | 특징(feature)를 선택할 수 있는 기능 제공 | \n",
    "| `sklearn.feature_extraction` | 특징(feature) 추출에 사용 |\n",
    "| `sklearn.decomposition` | 차원 축소 관련 알고리즘 지원 (PCA, NMF, Truncated SVD 등)\n",
    "| `sklearn.model_selection` | 교차 검증을 위해 데이터를 학습/테스트용으로 분리, 최적 파라미터를 추출하는 API 제공 (GridSearch 등)\n",
    "| `sklearn.metrics` | 분류, 회귀, 클러스터링, Pairwise에 대한 다양한 성능 측정 방법 제공 (Accuracy, Precision, Recall, ROC-AUC, RMSE 등) |\n",
    "| `sklearn.pipeline` | 특징 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 묶어서 실행할 수 있는 유틸리티 제공 |\n",
    "| `sklearn.linear_model` | 선형 회귀, 릿지(Ridge), 라쏘(Lasso), 로지스틱 회귀 등 회귀 관련 알고리즘과 SGD(Stochastic Gradient Descent) 알고리즘 제공 |\n",
    "| `sklearn.svm` | 서포트 벡터 머신 알고리즘 제공 |\n",
    "| `sklearn.neighbors` | 최근접 이웃 알고리즘 제공 (k-NN 등)\n",
    "| `sklearn.naive_bayes` | 나이브 베이즈 알고리즘 제공 (가우시안 NB, 다항 분포 NB 등) |\n",
    "| `sklearn.tree` | 의사 결정 트리 알고리즘 제공 |\n",
    "| `sklearn.ensemble` | 앙상블 알고리즘 제공 (Random Forest, AdaBoost, GradientBoost 등) |\n",
    "| `sklearn.cluster` | 비지도 클러스터링 알고리즘 제공 (k-Means, 계층형 클러스터링, DBSCAN 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df611cf8",
   "metadata": {},
   "source": [
    "## 연습용 데이터 세트\n",
    "\n",
    "### 분류 또는 회귀용 데이터 세트\n",
    "\n",
    "| API | 설명 |\n",
    "|-----|------|\n",
    "| `datasets.load_boston()` | 미국 보스턴의 집에 대한 특징과 가격 데이터 (회귀용) |\n",
    "| `datasets.load_iris()` | 붓꽃에 대한 특징을 가진 데이터 (분류용) |\n",
    "| `datasets.load_diabetes()` | 당뇨 데이터 (회귀용) |\n",
    "| `datasets.load_wine()` | 와인에 대한 특징을 가진 데이터 (분류용) |\n",
    "| `datasets.load_breast_cancer()` | 위스콘신 유방암 특징들과 악성/음성 레이블 데이터 (분류용) |\n",
    "| `datasets.load_digits()` | 0에서 9까지 숫자 이미지 픽셀 데이터 (분류용) |\n",
    "\n",
    "### 온라인 데이터 세트\n",
    "\n",
    "* 데이터 크기가 커서 온라인에서 데이터를 다운로드 한 후에 불러오는 예제 데이터 세트\n",
    "\n",
    "| API | 설명 |\n",
    "|-----|------|\n",
    "| `fetch_california_housing()` | 캘리포니아 주택 가격 데이터 |\n",
    "| `fetch_covtype()` | 회귀 분석용 토지 조사 데이터 |\n",
    "| `fetch_20newsgroups()` | 뉴스 그룹 텍스트 데이터 |\n",
    "| `fetch_olivetti_faces()` | 얼굴 이미지 데이터 |\n",
    "| `fetch_lfw_people()` | 얼굴 이미지 데이터 |\n",
    "| `fetch_lfw_paris()` | 얼굴 이미지 데이터 |\n",
    "| `fetch_rcv1()` | 로이터 뉴스 말뭉치 데이터 |\n",
    "| `fetch_mldata()` | ML 웹사이트에서 다운로드 |\n",
    "\n",
    "### 분류와 클러스터링을 위한 표본 데이터 생성\n",
    "\n",
    "| API | 설명 |\n",
    "|-----|------|\n",
    "| `datasets.make_classifications()` | 분류를 위한 데이터 세트 생성. 높은 상관도, 불필요한 속성 등의 노이즈를 고려한 데이터를 무작위로 생성 |\n",
    "| `datasets.make_blobs()` | 클러스터링을 위한 데이터 세트 생성. 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 셋트를 무작위로 생성 |\n",
    "\n",
    "### 예제 데이터 세트 구조\n",
    "\n",
    "* 일반적으로 딕셔너리 형태로 구성\n",
    "* data: 특징 데이터 세트\n",
    "* target: 분류용은 레이블 값, 회귀용은 숫자 결과값 데이터\n",
    "* target_names: 개별 레이블의 이름 (분류용)\n",
    "* feature_names: 특징 이름\n",
    "* DESCR: 데이터 세트에 대한 설명과 각 특징 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b5d6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "print(diabetes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6489fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d88d6",
   "metadata": {},
   "source": [
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b23b6d7",
   "metadata": {},
   "source": [
    "# 라이브러리 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fffe7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.datasets import load_iris, fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066182b4",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "scikit-learn은 CART 알고리즘(gini 사용)을 사용하여 이진트리를 생성\n",
    "\n",
    "gini 대신 entropy를 사용하려면, 생성자에 criterion='entropy' 인자로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d2ff18",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비 - 유방암 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd190a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys : \n",
      " dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer(as_frame = True)\n",
    "print(\"cancer.keys : \\n\", cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a099d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a96c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b5e376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325dabef",
   "metadata": {},
   "source": [
    "## 2. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d22dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size = .3, stratify = cancer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc8e664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 정확도 : 1.000\n",
      "test 정확도 : 0.906\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"train 정확도 : {0:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"test 정확도 : {0:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8396e0",
   "metadata": {},
   "source": [
    "### 규제 매개변수\n",
    "* max_depth : 트리 최대 깊이\n",
    "* min_samples_split : 분할되기 위해 노드가 가져야 하는 최소 샘플 수\n",
    "* min_samples_leaf : leaf node가 가지고 있어야할 최소 샘플 수\n",
    "* min_weight_fraction_leaf : min_samples_leaf와 비슷하지만, 가중치가 부여된 전체 샘플 수에서의 비율\n",
    "* max_leaf_nodes : leaf node의 총 최대 개수\n",
    "* max_features : 최상의 분할을 찾을 때 고려할 기능의 수\n",
    "\n",
    "\n",
    "#### min_으로 시작하는 매개변수 값 증가 -> 모델 규제 강화 -> 과적합 감소\n",
    "#### max_으로 시작하는 매개변수 값 감소 -> 모델 규제 강화 -> 과적합 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c98ffe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 정확도 : 0.997\n",
      "test 정확도 : 0.906\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 4)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"train 정확도 : {0:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"test 정확도 : {0:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e39d49",
   "metadata": {},
   "source": [
    "## 3. 트리 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f344793",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55aacd",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비 - 와인 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f89632ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "wine_df = pd.DataFrame(data = wine.data, columns = wine.feature_names)\n",
    "wine_df[\"target\"] = wine.target\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664eca87",
   "metadata": {},
   "source": [
    "## 2. 모델 생성, 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dfa3570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 일 때 정확도 : 0.639\n",
      "K =  3 일 때 정확도 : 0.722\n",
      "K =  5 일 때 정확도 : 0.694\n",
      "K =  10 일 때 정확도 : 0.750\n"
     ]
    }
   ],
   "source": [
    "X, y = wine.data, wine.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "\n",
    "for k in (1, 3, 5, 10):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"K = {0: d} 일 때 정확도 : {1:.3f}\".format(k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08eae26",
   "metadata": {},
   "source": [
    "### 표준화 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d750764",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "985a6b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 일 때 정확도 : 0.944\n",
      "K =  3 일 때 정확도 : 0.917\n",
      "K =  5 일 때 정확도 : 0.917\n",
      "K =  10 일 때 정확도 : 0.972\n"
     ]
    }
   ],
   "source": [
    "for k in (1, 3, 5, 10):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"K = {0: d} 일 때 정확도 : {1:.3f}\".format(k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c33c3",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeeb0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48b174a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0c7dd",
   "metadata": {},
   "source": [
    "## linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72eef3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(kernel = \"linear\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ae6ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 점수 : 0.989\n",
      "test 데이터 점수 : 0.974\n"
     ]
    }
   ],
   "source": [
    "print(\"train 데이터 점수 : {:.3f}\".format(model.score(X_train, y_train)))\n",
    "print(\"test 데이터 점수 : {:.3f}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0c3a7",
   "metadata": {},
   "source": [
    "## kernel SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e381dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(kernel = \"rbf\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "877c3941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 점수 : 0.987\n",
      "test 데이터 점수 : 0.982\n"
     ]
    }
   ],
   "source": [
    "print(\"train 데이터 점수 : {:.3f}\".format(model.score(X_train, y_train)))\n",
    "print(\"test 데이터 점수 : {:.3f}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8520ec7",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 분류기\n",
    "\n",
    "사이킷런의 naive_bayes 서브패키지에서는 다음과 같은 세가지 나이브베이즈 모형 클래스를 제공한다.\n",
    "\n",
    "* GaussianNB: 정규분포 나이브베이즈\n",
    "* BernoulliNB: 베르누이분포 나이브베이즈\n",
    "* MultinomialNB: 다항분포 나이브베이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc247b",
   "metadata": {},
   "source": [
    "## 가우시안 나이브 베이즈\n",
    "\n",
    "### 데이터 - iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a579063",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "model = GaussianNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2523253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류 결과표 : \n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "\n",
      "\n",
      "분류 보고서 : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.94      0.94      0.94        50\n",
      "           2       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       150\n",
      "   macro avg       0.96      0.96      0.96       150\n",
      "weighted avg       0.96      0.96      0.96       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"분류 결과표 : \\n\", confusion_matrix(y, y_pred), end = \"\\n\\n\\n\")\n",
    "print(\"분류 보고서 : \\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad3e37",
   "metadata": {},
   "source": [
    "## 다항 나이브 베이즈\n",
    "\n",
    "### 데이터 - 20 Newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52fda1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5922af08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\\nSubject: Pens fans reactions\\nOrganization: Post Office, Carnegie Mellon, Pittsburgh, PA\\nLines: 12\\nNNTP-Posting-Host: po4.andrew.cmu.edu\\n\\n\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\",\n",
       " 'From: mblawson@midway.ecn.uoknor.edu (Matthew B Lawson)\\nSubject: Which high-performance VLB video card?\\nSummary: Seek recommendations for VLB video card\\nNntp-Posting-Host: midway.ecn.uoknor.edu\\nOrganization: Engineering Computer Network, University of Oklahoma, Norman, OK, USA\\nKeywords: orchid, stealth, vlb\\nLines: 21\\n\\n  My brother is in the market for a high-performance video card that supports\\nVESA local bus with 1-2MB RAM.  Does anyone have suggestions/ideas on:\\n\\n  - Diamond Stealth Pro Local Bus\\n\\n  - Orchid Farenheit 1280\\n\\n  - ATI Graphics Ultra Pro\\n\\n  - Any other high-performance VLB card\\n\\n\\nPlease post or email.  Thank you!\\n\\n  - Matt\\n\\n-- \\n    |  Matthew B. Lawson <------------> (mblawson@essex.ecn.uoknor.edu)  |   \\n  --+-- \"Now I, Nebuchadnezzar, praise and exalt and glorify the King  --+-- \\n    |   of heaven, because everything he does is right and all his ways  |   \\n    |   are just.\" - Nebuchadnezzar, king of Babylon, 562 B.C.           |   \\n']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3851d",
   "metadata": {},
   "source": [
    "### 20 Newsgroup 데이터\n",
    "\n",
    "* 뉴스 기사가 어느 그룹에 속하는지 분류\n",
    "* 뉴스 기사는 텍스트 데이터이기 때문에 벡터 변환 필요\n",
    "\n",
    "#### 벡터화\n",
    "* 텍스트 데이터는 기계학습 모델에 입력 할 수 없음\n",
    "* 벡터화는 텍스트 데이터를 실수 벡터로 변환해 기계학습 모델에 입력 할 수 있도록 하는 전처리 과정\n",
    "* Scikit-learn에서는 Count, Hashing, Tf-idf 세가지 방법을 지원\n",
    "  - CountVectorizer\n",
    "    + 문서에 나온 단어의 수를 세서 벡터 생성\n",
    "    + 결과는 희소 행렬\n",
    "\n",
    "  - HashingVectorizer\n",
    "    + 각 단어를 해쉬 값으로 표현\n",
    "    + 미리 정해진 크기의 벡터로 표현\n",
    "\n",
    "  - TfidfVectorizer\n",
    "    + 문서에 나온 단어 빈도(term frequency)와 역문서 빈도(inverse document frequency)를 곱해서 구함\n",
    "    + 각 빈도는 일반적으로 로그 스케일링 후 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "119687bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Pipeline([(\"vect\", CountVectorizer()), (\"model\", MultinomialNB())])\n",
    "\n",
    "model2 = Pipeline([(\"vect\", TfidfVectorizer()), (\"model\", MultinomialNB())])\n",
    "\n",
    "model3 = Pipeline([(\"vect\", TfidfVectorizer(stop_words = \"english\")), (\"model\", MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b23b4576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fab54e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1_Mean score : 0.855\n",
      "Model2_Mean score : 0.856\n",
      "Model3_Mean score : 0.883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = news.data\n",
    "y = news.target\n",
    "\n",
    "for i, model in enumerate([model1, model2, model3]):\n",
    "    scores = cross_val_score(model, X, y, cv = 5)\n",
    "    print(\"Model{0:d}_Mean score : {1:.3f}\".format(i+1, np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
